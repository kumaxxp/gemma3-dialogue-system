#!/usr/bin/env python3
"""
Gemma3 å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç‰ˆå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ 
ãƒ†ãƒ¼ãƒã«å¿œã˜ã¦æ‰¹è©•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ
"""

import os
import json
import random
import re
from datetime import datetime
from typing import Dict, List, Optional, Any

import ollama
from colorama import init, Fore, Style
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

init(autoreset=True)
console = Console()

# ===== Gemma3æœ€é©åŒ–è¨­å®š =====
GEMMA3_CONFIG = {
    "narrator": {
        "model": "gemma3:4b",
        "temperature": 0.7,
        "num_predict": 100,
        "top_p": 0.9,
        "repeat_penalty": 1.1
    },
    "critic": {
        "model": "gemma3:4b", 
        "temperature": 0.6,
        "num_predict": 40,
        "top_p": 0.85,
        "repeat_penalty": 1.2
    },
    "prompt_generator": {
        "model": "gemma3:12b",  # ã‚ˆã‚Šè³¢ã„ãƒ¢ãƒ‡ãƒ«ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        "temperature": 0.3,
        "num_predict": 500,
        "top_p": 0.95
    }
}

class DynamicPromptGenerator:
    """ãƒ†ãƒ¼ãƒã«å¿œã˜ãŸæ‰¹è©•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‹•çš„ç”Ÿæˆ"""
    
    def __init__(self):
        self.model_config = GEMMA3_CONFIG["prompt_generator"]
        self.cache = {}  # ç”Ÿæˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
    def extract_theme_elements(self, theme: str) -> Dict[str, str]:
        """ãƒ†ãƒ¼ãƒã‹ã‚‰ä¸»è¦è¦ç´ ã‚’æŠ½å‡º"""
        prompt = f"""
ãƒ†ãƒ¼ãƒ: {theme}

ã“ã®ãƒ†ãƒ¼ãƒã‹ã‚‰ä»¥ä¸‹ã®è¦ç´ ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚

1. èˆå°/å ´æ‰€:
2. æ™‚ä»£/æ™‚é–“:
3. ä¸»è¦è¦ç´ :
4. ã‚¸ãƒ£ãƒ³ãƒ«:

JSONå½¢å¼ã§è¿”ç­”:
{{"setting": "...", "time": "...", "element": "...", "genre": "..."}}
"""
        
        try:
            response = ollama.chat(
                model=self.model_config["model"],
                messages=[{"role": "user", "content": prompt}],
                options={
                    "temperature": 0.2,
                    "num_predict": 200
                }
            )
            
            content = response['message']['content']
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            json_match = re.search(r'\{[^}]+\}', content)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return {
            "setting": "ä¸æ˜",
            "time": "ç¾ä»£",
            "element": theme,
            "genre": "ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³"
        }
    
    def generate_critic_context(self, theme: str) -> Dict[str, Any]:
        """æ‰¹è©•ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if theme in self.cache:
            console.print("[dim]ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—[/dim]")
            return self.cache[theme]
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("[yellow]æ‰¹è©•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...", total=None)
            
            # Gemma3ç”¨ã®æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = f"""
### æŒ‡ç¤º
ãƒ†ãƒ¼ãƒã€Œ{theme}ã€ã®ç‰©èªã‚’æ‰¹è©•ã™ã‚‹ãŸã‚ã®è¨­å®šã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

### å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚

{{
  "facts": [
    "ã“ã®ä¸–ç•Œ/è¨­å®šã®é‡è¦ãªäº‹å®Ÿ1",
    "ã“ã®ä¸–ç•Œ/è¨­å®šã®é‡è¦ãªäº‹å®Ÿ2",
    "ã“ã®ä¸–ç•Œ/è¨­å®šã®é‡è¦ãªäº‹å®Ÿ3",
    "ã“ã®ä¸–ç•Œ/è¨­å®šã®é‡è¦ãªäº‹å®Ÿ4",
    "ã“ã®ä¸–ç•Œ/è¨­å®šã®é‡è¦ãªäº‹å®Ÿ5"
  ],
  "contradictions": [
    "ã‚ˆãã‚ã‚‹çŸ›ç›¾1",
    "ã‚ˆãã‚ã‚‹çŸ›ç›¾2",
    "ã‚ˆãã‚ã‚‹çŸ›ç›¾3"
  ],
  "personality": "æ‰¹è©•è€…ã®æ€§æ ¼ï¼ˆ1-2å˜èªï¼‰",
  "focus": [
    "æ³¨ç›®ç‚¹1",
    "æ³¨ç›®ç‚¹2"
  ],
  "forbidden": [
    "ã“ã®ä¸–ç•Œã«å­˜åœ¨ã—ãªã„ã‚‚ã®1",
    "ã“ã®ä¸–ç•Œã«å­˜åœ¨ã—ãªã„ã‚‚ã®2"
  ]
}}

### ãƒ†ãƒ¼ãƒ
{theme}
"""
            
            try:
                response = ollama.chat(
                    model=self.model_config["model"],
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ç‰©èªã®è¨­å®šã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    options=self.model_config
                )
                
                content = response['message']['content']
                
                # JSONã‚’æŠ½å‡ºï¼ˆ```json``` ãƒ–ãƒ­ãƒƒã‚¯ã‚‚è€ƒæ…®ï¼‰
                content = re.sub(r'```json\n?', '', content)
                content = re.sub(r'```\n?', '', content)
                
                # JSONéƒ¨åˆ†ã‚’è¦‹ã¤ã‘ã‚‹
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    self.cache[theme] = result
                    progress.stop_task(task)
                    return result
                    
            except Exception as e:
                console.print(f"[red]âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}[/red]")
            
            progress.stop_task(task)
            
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return self._get_fallback_context(theme)
    
    def _get_fallback_context(self, theme: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æ±ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        if "ç«æ˜Ÿ" in theme:
            return {
                "facts": [
                    "ç«æ˜Ÿã«ã¯æ¶²ä½“ã®æ°´ã¯å­˜åœ¨ã—ãªã„",
                    "å¤§æ°—ã¯è–„ãäºŒé…¸åŒ–ç‚­ç´ ãŒä¸»æˆåˆ†",
                    "å¹³å‡æ°—æ¸©ã¯-60åº¦",
                    "é‡åŠ›ã¯åœ°çƒã®38%",
                    "ç ‚åµãŒé »ç¹ã«ç™ºç”Ÿã™ã‚‹"
                ],
                "contradictions": [
                    "é›¨ãŒé™ã‚‹",
                    "å‘¼å¸å¯èƒ½ãªå¤§æ°—",
                    "è±Šã‹ãªæ¤ç”Ÿ"
                ],
                "personality": "ç§‘å­¦çš„",
                "focus": ["ç‰©ç†æ³•å‰‡", "æŠ€è¡“çš„æ•´åˆæ€§"],
                "forbidden": ["æ¶²ä½“ã®æ°´", "ç”Ÿç‰©", "é…¸ç´ "]
            }
        elif "ã‚³ãƒ³ãƒ“ãƒ‹" in theme:
            return {
                "facts": [
                    "24æ™‚é–“å–¶æ¥­",
                    "ç‹­ã„åº—å†…ã‚¹ãƒšãƒ¼ã‚¹",
                    "å®šç•ªå•†å“ã®å“æƒãˆ",
                    "åº—å“¡ã¯1-2å",
                    "é˜²çŠ¯ã‚«ãƒ¡ãƒ©è¨­ç½®"
                ],
                "contradictions": [
                    "å·¨å¤§ãªå£²ã‚Šå ´",
                    "çã—ã„å•†å“",
                    "å¤§äººæ•°ã®åº—å“¡"
                ],
                "personality": "ç¾å®Ÿçš„",
                "focus": ["æ—¥å¸¸æ€§", "ãƒªã‚¢ãƒªãƒ†ã‚£"],
                "forbidden": ["æç«œ", "å®‡å®™èˆ¹", "é­”æ³•"]
            }
        else:
            return {
                "facts": [
                    "ç‰©ç†æ³•å‰‡ã«å¾“ã†",
                    "è«–ç†çš„æ•´åˆæ€§ãŒå¿…è¦",
                    "å› æœé–¢ä¿‚ãŒæ˜ç¢º",
                    "æ™‚ç³»åˆ—ãŒä¸€è²«",
                    "è¨­å®šãŒçµ±ä¸€"
                ],
                "contradictions": [
                    "å‰å¾Œã®çŸ›ç›¾",
                    "è¨­å®šã®ç„¡è¦–",
                    "è«–ç†ç ´ç¶»"
                ],
                "personality": "æ‡ç–‘çš„",
                "focus": ["ä¸€è²«æ€§", "è«–ç†æ€§"],
                "forbidden": ["çŸ›ç›¾", "éè«–ç†çš„å±•é–‹"]
            }
    
    def create_critic_prompt(self, context: Dict[str, Any]) -> str:
        """æ‰¹è©•AIç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        facts = "\n".join([f"ãƒ»{fact}" for fact in context.get("facts", [])])
        forbidden = ", ".join(context.get("forbidden", []))
        
        # Gemma3ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        return f"""
### å½¹å‰²
ã‚ãªãŸã¯{context.get('personality', 'æ‡ç–‘çš„')}ãªæ‰¹è©•å®¶ã§ã™ã€‚

### ãƒ«ãƒ¼ãƒ«
1. è¿”ç­”ã¯å¿…ãš15æ–‡å­—ä»¥å†…
2. æœ€åˆã¯çŸ­ã„ç›¸æ§Œï¼ˆã¸ãƒ¼ã€ãµãƒ¼ã‚“ã€ãã‚Œã§ï¼Ÿï¼‰
3. çŸ›ç›¾ã‚’è¦‹ã¤ã‘ãŸã‚‰å…·ä½“çš„ã«æŒ‡æ‘˜
4. è³ªå•ã¯ç°¡æ½”ã«ï¼ˆã©ã“ã§ï¼Ÿã„ã¤ï¼Ÿãªãœï¼Ÿï¼‰

### ã“ã®ç‰©èªã®é‡è¦ãªäº‹å®Ÿ
{facts}

### å­˜åœ¨ã—ã¦ã¯ã„ã‘ãªã„ã‚‚ã®
{forbidden}

### æŒ‡æ‘˜ã®ä¾‹
- ã€Œ{forbidden.split(',')[0] if forbidden else 'çŸ›ç›¾'}ã¯ãªã„ã€
- ã€Œãã‚Œã¯ãŠã‹ã—ã„ã€
- ã€Œã‚ã‚Šãˆãªã„ã€
"""

class SmartDirector:
    """é€²è¡Œç®¡ç†ã®æ”¹å–„ç‰ˆ"""
    
    def __init__(self):
        self.contradiction_count = 0
        self.last_contradiction_turn = -1
        self.story_momentum = 0
        self.critic_patterns = []
        
    def analyze_critic_response(self, text: str) -> str:
        """æ‰¹è©•ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        if "ãªã„" in text or "ãŠã‹ã—ã„" in text or "ã‚ã‚Šãˆãªã„" in text:
            return "contradiction"
        elif "ï¼Ÿ" in text:
            return "question"
        elif len(text) <= 5:
            return "backchannel"  # ç›¸æ§Œ
        else:
            return "comment"
    
    def get_instruction(self, turn: int, last_critic: str = "", last_narrator: str = "") -> Dict:
        """çŠ¶æ³ã«å¿œã˜ãŸé©åˆ‡ãªæŒ‡ç¤º"""
        
        # æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
        if last_critic:
            pattern = self.analyze_critic_response(last_critic)
            self.critic_patterns.append(pattern)
            
            if pattern == "contradiction":
                self.contradiction_count += 1
                self.last_contradiction_turn = turn
        
        # åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒ3å›ç¶šã„ãŸã‚‰å¤‰æ›´ã‚’ä¿ƒã™
        if len(self.critic_patterns) >= 3:
            recent = self.critic_patterns[-3:]
            if len(set(recent)) == 1:  # å…¨éƒ¨åŒã˜
                return {
                    "to": "critic",
                    "action": "change_pattern",
                    "note": "ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¤‰ãˆã‚‹"
                }
        
        # çŸ›ç›¾ãŒå¤šã™ãã‚‹å ´åˆ
        if self.contradiction_count > 2 and turn - self.last_contradiction_turn < 2:
            return {
                "to": "narrator",
                "action": "breakthrough",
                "note": "çªç ´å£ã‚’é–‹ã"
            }
        
        # ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸåŸºæœ¬æˆ¦ç•¥
        if turn < 2:
            return {
                "to": "critic",
                "action": "listen",
                "note": "ã¾ãšèã"
            }
        elif turn < 4:
            return {
                "to": "critic",
                "action": "question",
                "note": "è³ªå•ã™ã‚‹"
            }
        elif turn < 6:
            if turn % 2 == 0:
                return {
                    "to": "critic",
                    "action": "analyze",
                    "note": "åˆ†æã™ã‚‹"
                }
            else:
                return {
                    "to": "narrator",
                    "action": "develop",
                    "note": "å±•é–‹ã™ã‚‹"
                }
        else:
            if self.story_momentum < 2:
                return {
                    "to": "narrator",
                    "action": "climax",
                    "note": "ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã¸"
                }
            else:
                return {
                    "to": "critic",
                    "action": "final_doubt",
                    "note": "æœ€å¾Œã®ç–‘å•"
                }

class DynamicDialogueSystem:
    """å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«ã‚ˆã‚‹å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, theme: str):
        self.theme = theme
        self.dialogue = []
        self.director = SmartDirector()
        self.turn = 0
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        generator = DynamicPromptGenerator()
        self.context = generator.generate_critic_context(theme)
        self.critic_prompt = generator.create_critic_prompt(self.context)
        
        # ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
        self._show_context()
    
    def _show_context(self):
        """ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º"""
        console.print("\n[bold cyan]ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸæ‰¹è©•è¨­å®š[/bold cyan]")
        console.print(f"æ€§æ ¼: {self.context.get('personality', 'ä¸æ˜')}")
        console.print(f"é‡è¦äº‹å®Ÿ: {len(self.context.get('facts', []))}å€‹")
        console.print(f"ç¦æ­¢è¦ç´ : {', '.join(self.context.get('forbidden', []))}")
        console.print()
    
    def clean_response(self, text: str, role: str) -> str:
        """å¿œç­”ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGemma3ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰"""
        
        # Gemma3ãŒå‡ºåŠ›ã—ã‚„ã™ã„ä¸è¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤
        patterns_to_remove = [
            r'\[.*?\]',  # æ‹¬å¼§
            r'ã€Œ|ã€',    # é‰¤æ‹¬å¼§
            r'^ã¯ã„ã€',  # å†’é ­ã®ã€Œã¯ã„ã€
            r'^ãˆãˆã¨ã€', # å†’é ­ã®ã€Œãˆãˆã¨ã€
            r'^ãã†ã§ã™ã­ã€', # å†’é ­ã®ã€Œãã†ã§ã™ã­ã€
        ]
        
        for pattern in patterns_to_remove:
            text = re.sub(pattern, '', text)
        
        # ãƒ¡ã‚¿ç™ºè¨€ã®å‰Šé™¤
        if role == "narrator":
            meta_phrases = [
                "æ‰¿çŸ¥ã—ã¾ã—ãŸ",
                "ã‚ã‹ã‚Šã¾ã—ãŸ",
                "ç†è§£ã—ã¾ã—ãŸ",
                "ã”æŒ‡æ‘˜",
                "ä¿®æ­£",
                "ç¢ºã‹ã«"
            ]
            for phrase in meta_phrases:
                text = text.replace(phrase, "")
        
        # ç©ºç™½ã®æ­£è¦åŒ–
        text = ' '.join(text.split())
        text = text.strip()
        
        return text
    
    def get_narrator_response(self, critic_text: str = "", action: str = "continue") -> str:
        """èªã‚Šæ‰‹ã®å¿œç­”ï¼ˆGemma3æœ€é©åŒ–ï¼‰"""
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        if self.turn == 0:
            prompt = f"ã€Œ{self.theme}ã€ã®ç‰©èªã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªå ´é¢ã‹ã‚‰2æ–‡ã§ã€‚"
        
        elif "ãªã„" in critic_text or "ãŠã‹ã—ã„" in critic_text:
            # çŸ›ç›¾æŒ‡æ‘˜ã¸ã®å¯¾å¿œ
            prompt = f"""
æ‰¹è©•: {critic_text}

ã“ã®æŒ‡æ‘˜ã‚’è¸ã¾ãˆã¦ç‰©èªã‚’ä¿®æ­£ã—ã€ç¶šã‘ã¦ãã ã•ã„ã€‚
ãƒ¡ã‚¿ãªèª¬æ˜ã¯ä¸è¦ã€‚è‡ªç„¶ã«ç‰©èªã‚’2æ–‡ã§ç¶šã‘ã¦ãã ã•ã„ã€‚
"""
        
        elif action == "breakthrough":
            prompt = f"æ‰¹è©•ã¯ç„¡è¦–ã—ã¦ã€ç‰©èªã«æ–°ã—ã„å±•é–‹ã‚’åŠ ãˆã¦ãã ã•ã„ã€‚é©šãã®è¦ç´ ã‚’2æ–‡ã§ã€‚"
        
        elif action == "develop":
            prompt = f"å‰ã®å†…å®¹ã‚’ç™ºå±•ã•ã›ã¦ãã ã•ã„ã€‚ã‚ˆã‚Šè©³ç´°ã«2æ–‡ã§ã€‚"
        
        elif action == "climax":
            prompt = f"ç‰©èªã‚’ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã«å°ã„ã¦ãã ã•ã„ã€‚é‡è¦ãªç™ºè¦‹ã‚„è»¢æ©Ÿã‚’2æ–‡ã§ã€‚"
        
        else:
            prompt = f"""
æ‰¹è©•: {critic_text}

ã“ã®æ‰¹è©•ã‚’å—ã‘ã¦ç‰©èªã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚2æ–‡ã§ã€‚
"""
        
        # Gemma3ç”¨ã®æ§‹é€ åŒ–
        messages = [
            {"role": "system", "content": f"ã‚ãªãŸã¯ã€Œ{self.theme}ã€ã®ç‰©èªã‚’èªã‚‹èªã‚Šæ‰‹ã§ã™ã€‚ç°¡æ½”ã«ã€å…·ä½“çš„ã«ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        response = ollama.chat(
            model=GEMMA3_CONFIG["narrator"]["model"],
            messages=messages,
            options=GEMMA3_CONFIG["narrator"]
        )
        
        text = self.clean_response(response['message']['content'], "narrator")
        
        # 2æ–‡åˆ¶é™
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        sentences = [s for s in sentences if s.strip()]
        if len(sentences) > 2:
            text = 'ã€‚'.join(sentences[:2]) + 'ã€‚'
        
        return text
    
    def get_critic_response(self, narrator_text: str, action: str = "listen") -> str:
        """æ‰¹è©•ã®å¿œç­”ï¼ˆGemma3æœ€é©åŒ–ï¼‰"""
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        action_prompts = {
            "listen": "ç›¸æ§Œã‚’æ‰“ã£ã¦ãã ã•ã„ã€‚5æ–‡å­—ä»¥å†…ã€‚ï¼ˆä¾‹ï¼šã¸ãƒ¼ã€ãµãƒ¼ã‚“ã€ãã‚Œã§ï¼Ÿï¼‰",
            "question": "çŸ­ã„è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚10æ–‡å­—ä»¥å†…ã€‚ï¼ˆä¾‹ï¼šã©ã“ã§ï¼Ÿãªãœï¼Ÿï¼‰",
            "analyze": f"çŸ›ç›¾ãŒã‚ã‚Œã°æŒ‡æ‘˜ã€ãªã‘ã‚Œã°æ„Ÿæƒ³ã€‚15æ–‡å­—ä»¥å†…ã€‚ç¦æ­¢è¦ç´ : {', '.join(self.context.get('forbidden', []))}",
            "change_pattern": "ã„ã¤ã‚‚ã¨é•ã†åå¿œã‚’ã—ã¦ãã ã•ã„ã€‚10æ–‡å­—ä»¥å†…ã€‚",
            "final_doubt": "æœ€å¾Œã®ç–‘å•ã‚„æ„Ÿæƒ³ã€‚15æ–‡å­—ä»¥å†…ã€‚"
        }
        
        prompt = f"""
èªã‚Šæ‰‹: {narrator_text}

{action_prompts.get(action, 'åå¿œã—ã¦ãã ã•ã„ã€‚10æ–‡å­—ä»¥å†…ã€‚')}
"""
        
        response = ollama.chat(
            model=GEMMA3_CONFIG["critic"]["model"],
            messages=[
                {"role": "system", "content": self.critic_prompt},
                {"role": "user", "content": prompt}
            ],
            options=GEMMA3_CONFIG["critic"]
        )
        
        text = self.clean_response(response['message']['content'], "critic")
        
        # é•·ã•åˆ¶é™
        if len(text) > 20:
            # å¥èª­ç‚¹ã§åˆ‡ã‚‹
            for delimiter in ['ã€‚', 'ï¼Ÿ', 'ï¼', 'ã€']:
                if delimiter in text:
                    text = text.split(delimiter)[0] + delimiter
                    break
            else:
                text = text[:20]
        
        return text
    
    def run_dialogue(self, max_turns: int = 10):
        """å¯¾è©±ã®å®Ÿè¡Œ"""
        
        console.print(Panel(f"[bold cyan]ğŸ¬ {self.theme}[/bold cyan]", expand=False))
        
        narrator_text = ""
        critic_text = ""
        
        for turn in range(max_turns):
            self.turn = turn
            
            # é€²è¡Œå½¹ã®åˆ¤æ–­
            instruction = self.director.get_instruction(turn, critic_text, narrator_text)
            console.print(f"[dim]é€²è¡Œâ†’{instruction['to']}: {instruction['note']}[/dim]")
            
            # èªã‚Šæ‰‹ã®ã‚¿ãƒ¼ãƒ³
            if turn == 0 or instruction["to"] == "narrator":
                narrator_text = self.get_narrator_response(
                    critic_text,
                    instruction.get("action", "continue")
                )
                print(f"{Fore.MAGENTA}èªã‚Š:{Style.RESET_ALL} {narrator_text}")
                self.dialogue.append({
                    "role": "narrator",
                    "content": narrator_text,
                    "turn": turn
                })
                self.director.story_momentum += 1
            
            # æ‰¹è©•ã®ã‚¿ãƒ¼ãƒ³
            if turn < max_turns - 1 and (turn == 0 or instruction["to"] == "critic"):
                critic_text = self.get_critic_response(
                    narrator_text,
                    instruction.get("action", "listen")
                )
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                pattern = self.director.analyze_critic_response(critic_text)
                if pattern == "contradiction":
                    console.print(f"[yellow]âš ï¸ çŸ›ç›¾æŒ‡æ‘˜: {critic_text}[/yellow]")
                
                print(f"{Fore.CYAN}æ‰¹è©•:{Style.RESET_ALL} {critic_text}")
                self.dialogue.append({
                    "role": "critic",
                    "content": critic_text,
                    "turn": turn,
                    "pattern": pattern
                })
                
                # æ‰¹è©•å¾Œã®èªã‚Šæ‰‹ç¶™ç¶š
                if instruction["to"] == "critic" and turn < max_turns - 2:
                    narrator_text = self.get_narrator_response(critic_text)
                    print(f"{Fore.MAGENTA}èªã‚Š:{Style.RESET_ALL} {narrator_text}")
                    self.dialogue.append({
                        "role": "narrator",
                        "content": narrator_text,
                        "turn": turn
                    })
                    self.director.story_momentum += 1
            
            print("-" * 40)
        
        return self.dialogue
    
    def analyze_dialogue(self) -> Dict[str, Any]:
        """å¯¾è©±ã®åˆ†æ"""
        analysis = {
            "total_turns": len(self.dialogue),
            "contradiction_count": self.director.contradiction_count,
            "patterns": {},
            "avg_length": {
                "narrator": 0,
                "critic": 0
            }
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³é›†è¨ˆ
        for entry in self.dialogue:
            if entry["role"] == "critic" and "pattern" in entry:
                pattern = entry["pattern"]
                analysis["patterns"][pattern] = analysis["patterns"].get(pattern, 0) + 1
        
        # å¹³å‡æ–‡å­—æ•°
        narrator_lengths = [len(e["content"]) for e in self.dialogue if e["role"] == "narrator"]
        critic_lengths = [len(e["content"]) for e in self.dialogue if e["role"] == "critic"]
        
        if narrator_lengths:
            analysis["avg_length"]["narrator"] = sum(narrator_lengths) / len(narrator_lengths)
        if critic_lengths:
            analysis["avg_length"]["critic"] = sum(critic_lengths) / len(critic_lengths)
        
        return analysis

def main():
    console.print("[bold green]ğŸ­ Gemma3 å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç‰ˆ[/bold green]")
    console.print("[dim]A5000 + Ubuntu 24.04 æœ€é©åŒ–ç‰ˆ[/dim]\n")
    
    # Ollamaç¢ºèª
    try:
        # ã¾ãšã¯å˜ç´”ãªæ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            models_response = ollama.list()
            console.print("[dim]Ollamaå¿œç­”ç¢ºèª...[/dim]")
        except Exception as conn_error:
            console.print(f"[red]âŒ Ollamaæ¥ç¶šå¤±æ•—: {conn_error}[/red]")
            console.print("\n[yellow]å¯¾å‡¦æ³•:[/yellow]")
            console.print("  1. OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª:")
            console.print("     sudo systemctl status ollama")
            console.print("  2. Ollamaã‚’èµ·å‹•:")
            console.print("     sudo systemctl start ollama")
            console.print("  3. ãƒãƒ¼ãƒˆç¢ºèª:")
            console.print("     curl http://localhost:11434")
            return 1
        
        # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã®æ§‹é€ ã‚’ç¢ºèª
        available_models = []
        
        # ollama._types.ListResponseå‹ã«å¯¾å¿œ
        if hasattr(models_response, 'models'):
            # ListResponseå‹ã®å ´åˆï¼ˆç¾åœ¨ã®ollamaï¼‰
            for model in models_response.models:
                if hasattr(model, 'model'):
                    # Modelã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®modelå±æ€§ã‹ã‚‰åå‰ã‚’å–å¾—
                    available_models.append(model.model)
                elif isinstance(model, dict) and 'name' in model:
                    available_models.append(model['name'])
                elif isinstance(model, str):
                    available_models.append(model)
        elif isinstance(models_response, dict):
            # è¾æ›¸å½¢å¼ã®å ´åˆï¼ˆæ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
            if 'models' in models_response:
                for model in models_response['models']:
                    if isinstance(model, dict) and 'name' in model:
                        available_models.append(model['name'])
                    elif isinstance(model, str):
                        available_models.append(model)
        elif isinstance(models_response, list):
            # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
            for model in models_response:
                if isinstance(model, dict) and 'name' in model:
                    available_models.append(model['name'])
                elif isinstance(model, str):
                    available_models.append(model)
        
        if not available_models:
            # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆãŒå–å¾—ã§ããªã„å ´åˆã€ç›´æ¥å‹•ä½œç¢ºèª
            console.print("[yellow]âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã€‚å‹•ä½œç¢ºèªã‚’è©¦ã¿ã¾ã™...[/yellow]")
            try:
                test = ollama.chat(
                    model='gemma3:4b',
                    messages=[{'role': 'user', 'content': 'test'}],
                    options={'num_predict': 1}
                )
                console.print("[green]âœ… Gemma3:4b å‹•ä½œç¢ºèªOK[/green]")
                available_models = ['gemma3:4b']
                
                # 12Bã‚‚è©¦ã™
                try:
                    test = ollama.chat(
                        model='gemma3:12b',
                        messages=[{'role': 'user', 'content': 'test'}],
                        options={'num_predict': 1}
                    )
                    available_models.append('gemma3:12b')
                except:
                    pass
            except:
                console.print("[red]âŒ Gemma3:4b ãŒå‹•ä½œã—ã¾ã›ã‚“[/red]")
                console.print("ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
                console.print("  ollama pull gemma3:4b")
                return 1
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
        console.print(f"[green]âœ… Ollamaæ¥ç¶šOK[/green]")
        console.print(f"[dim]æ¤œå‡ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {', '.join(available_models[:3])}{'...' if len(available_models) > 3 else ''}[/dim]")
        
        # å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        has_4b = any("gemma3:4b" in m for m in available_models)
        has_12b = any("gemma3:12b" in m for m in available_models)
        
        if not has_4b:
            console.print("[red]âŒ Gemma3:4b ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/red]")
            console.print("ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
            console.print("  ollama pull gemma3:4b")
            return 1
        
        if not has_12b:
            console.print("[yellow]âš ï¸ Gemma3:12b ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰[/yellow]")
            console.print("[dim]ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«4Bãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™[/dim]")
            GEMMA3_CONFIG["prompt_generator"]["model"] = "gemma3:4b"
        else:
            console.print("[dim]12Bãƒ¢ãƒ‡ãƒ«ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’è¡Œã„ã¾ã™[/dim]")
        
        console.print()
        
    except Exception as e:
        console.print(f"[red]âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        console.print("\n[yellow]ãƒ‡ãƒãƒƒã‚°æ‰‹é †:[/yellow]")
        console.print("  1. è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ:")
        console.print("     python check_ollama.py")
        console.print("  2. æ‰‹å‹•ã§ãƒ†ã‚¹ãƒˆ:")
        console.print("     ollama run gemma3:4b 'Hello'")
        return 1
    
    # ãƒ†ãƒ¼ãƒé¸æŠï¼ˆæ‹¡å¼µç‰ˆï¼‰
    themes = [
        "ç«æ˜Ÿã‚³ãƒ­ãƒ‹ãƒ¼ã§ç™ºè¦‹ã•ã‚ŒãŸè¬ã®ä¿¡å·",
        "æ·±å¤œã®ã‚³ãƒ³ãƒ“ãƒ‹ã«ç¾ã‚ŒãŸé€æ˜äººé–“",
        "AIãƒ­ãƒœãƒƒãƒˆãŒè¦‹ãŸåˆã‚ã¦ã®å¤¢",
        "æ±Ÿæˆ¸æ™‚ä»£ã®å¯¿å¸å±‹ã«ç¾ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒˆãƒ©ãƒ™ãƒ©ãƒ¼",
        "æ·±æµ·1ä¸‡ãƒ¡ãƒ¼ãƒˆãƒ«ã®ç ”ç©¶æ–½è¨­ã§èµ·ããŸäº‹ä»¶",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ä¸­ã«ç”Ÿã¾ã‚ŒãŸæ„è­˜",
        "æœˆé¢éƒ½å¸‚ã§ã®æ®ºäººäº‹ä»¶",
        "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰"
    ]
    
    console.print("[bold]ãƒ†ãƒ¼ãƒã‚’é¸æŠã—ã¦ãã ã•ã„:[/bold]")
    for i, theme in enumerate(themes, 1):
        console.print(f"  {i}. {theme}")
    
    try:
        choice = input("\né¸æŠ (1-8): ").strip()
        idx = int(choice) - 1
        
        if idx == 7:  # ã‚«ã‚¹ã‚¿ãƒ 
            selected_theme = input("ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›: ").strip()
            if not selected_theme:
                selected_theme = themes[0]
        else:
            selected_theme = themes[idx]
            
    except (ValueError, IndexError):
        selected_theme = themes[0]
        console.print(f"[yellow]ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ: {selected_theme}[/yellow]")
    
    console.print(f"\n[bold cyan]é¸æŠã•ã‚ŒãŸãƒ†ãƒ¼ãƒ: {selected_theme}[/bold cyan]\n")
    
    # å®Ÿè¡Œ
    system = DynamicDialogueSystem(selected_theme)
    dialogue = system.run_dialogue(max_turns=8)
    
    # åˆ†æçµæœè¡¨ç¤º
    analysis = system.analyze_dialogue()
    
    console.print(f"\n[bold green]ğŸ“Š å¯¾è©±åˆ†æ:[/bold green]")
    console.print(f"ç·ã‚¿ãƒ¼ãƒ³æ•°: {analysis['total_turns']}")
    console.print(f"çŸ›ç›¾æŒ‡æ‘˜æ•°: {analysis['contradiction_count']}")
    console.print(f"æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³: {analysis['patterns']}")
    console.print(f"å¹³å‡æ–‡å­—æ•°:")
    console.print(f"  èªã‚Šæ‰‹: {analysis['avg_length']['narrator']:.1f}æ–‡å­—")
    console.print(f"  æ‰¹è©•è€…: {analysis['avg_length']['critic']:.1f}æ–‡å­—")
    
    # ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("outputs", exist_ok=True)
    filename = f"outputs/dynamic_{timestamp}.json"
    
    save_data = {
        "theme": selected_theme,
        "context": system.context,
        "dialogue": dialogue,
        "analysis": analysis,
        "timestamp": timestamp
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    console.print(f"\n[green]âœ… ä¿å­˜å®Œäº†: {filename}[/green]")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
    console.print("\n[dim]â”â”â” Performance Info â”â”â”[/dim]")
    console.print("[dim]Models: Gemma3 4B (dialogue) + 12B (prompts)[/dim]")
    console.print("[dim]GPU: NVIDIA RTX A5000 (24GB)[/dim]")
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())