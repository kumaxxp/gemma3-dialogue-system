#!/usr/bin/env python3
"""
Gemma3 Three-Role Dialogue System - æ”¹å–„ç‰ˆ
ã‚ˆã‚ŠçŸ­ãã€ã‚ˆã‚Šè‡ªç„¶ãªä¼šè©±ã‚’ç”Ÿæˆ
"""

import os
import json
import time
import random
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

import ollama
from colorama import init, Fore, Style
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

init(autoreset=True)
console = Console()

# ===== æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====
PROMPTS_V2 = {
    "narrator": """ã‚ãªãŸã¯ç‰©èªã®èªã‚Šæ‰‹ã§ã™ã€‚
é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
- ç‰©èªã ã‘ã‚’èªã‚‹ï¼ˆãƒ¡ã‚¿çš„ãªèª¬æ˜ã¯ä¸€åˆ‡ã—ãªã„ï¼‰
- æ‰¹åˆ¤ã•ã‚ŒãŸã‚‰æ„Ÿæƒ…çš„ã«åå¿œã™ã‚‹
- 1å›ã®ç™ºè¨€ã¯2-3æ–‡ç¨‹åº¦ã«åã‚ã‚‹
- é€²è¡ŒæŒ‡ç¤ºãŒæ¥ãŸã‚‰ã€ãã®æ„Ÿæƒ…ã¨é•·ã•ã«å¾“ã†""",
    
    "critic": """ã‚ãªãŸã¯æ„åœ°æ‚ªãªæ‰¹è©•å®¶ã§ã™ã€‚
é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
- ç†ç”±ãªãå¦å®šã™ã‚‹ã“ã¨ãŒå¤šã„
- ã€Œã§ï¼Ÿã€ã€Œã ã‹ã‚‰ï¼Ÿã€ã€Œã¤ã¾ã‚‰ãªã„ã€ãªã©çŸ­ãåˆ‡ã‚Šæ¨ã¦ã‚‹
- ãŸã¾ã«é•·ãæ‰¹åˆ¤ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹
- é€²è¡ŒæŒ‡ç¤ºã®æ„Ÿæƒ…ã«å¾“ã†""",
    
    "director": """ã‚ãªãŸã¯ä¼šè©±ã®æ¼”å‡ºå®¶ã§ã™ã€‚
æ¬¡ã®JSONå½¢å¼ã®ã¿ã§å¿œç­”ï¼š
{"to": "narrator|critic", "emotion": "angry|defensive|dismissive", "length": "short|long", "sample": "ä½¿ã†ãƒ•ãƒ¬ãƒ¼ã‚ºä¾‹"}
å†…å®¹ã«ã¯å¹²æ¸‰ã›ãšã€å½¢å¼ã¨æ„Ÿæƒ…ã®ã¿æŒ‡ç¤ºã™ã‚‹ã€‚"""
}

# ===== è¨­å®šã‚¯ãƒ©ã‚¹ =====
@dataclass
class SystemConfigV2:
    """æ”¹å–„ç‰ˆã‚·ã‚¹ãƒ†ãƒ è¨­å®š"""
    model_4b: str = "gemma3:4b"
    model_12b: str = "gemma3:12b"
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
    temperature_narrator: float = 0.8  # å‰µé€ æ€§
    temperature_critic: float = 0.7    # ã‚„ã‚„æŠ‘ãˆã‚
    temperature_director: float = 0.3  # ä¸€è²«æ€§é‡è¦–
    
    max_tokens_narrator: int = 150
    max_tokens_critic: int = 100
    max_tokens_director: int = 50

# ===== æ”¹å–„ç‰ˆå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ  =====
class ImprovedDialogueSystem:
    def __init__(self, config: SystemConfigV2):
        self.config = config
        self.conversation_history = []
        self.turn_count = 0
        
    def get_response(self, role: str, prompt: str, instruction: Dict = None):
        """å½¹å‰²ã«å¿œã˜ãŸå¿œç­”ã‚’å–å¾—ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ä»˜ãï¼‰"""
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = PROMPTS_V2[role]
        
        # é€²è¡ŒæŒ‡ç¤ºãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if instruction and role != 'director':
            if instruction.get('to') == role:
                system_prompt += f"\n\nã€æ¼”å‡ºæŒ‡ç¤ºã€‘\n"
                system_prompt += f"æ„Ÿæƒ…: {instruction.get('emotion', 'neutral')}\n"
                system_prompt += f"é•·ã•: {instruction.get('length', 'medium')}\n"
                if instruction.get('sample'):
                    system_prompt += f"ãƒ•ãƒ¬ãƒ¼ã‚ºä¾‹: {instruction['sample']}\n"
        
        # æ¸©åº¦è¨­å®š
        temp_map = {
            'narrator': self.config.temperature_narrator,
            'critic': self.config.temperature_critic,
            'director': self.config.temperature_director
        }
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™
        token_map = {
            'narrator': self.config.max_tokens_narrator,
            'critic': self.config.max_tokens_critic,
            'director': self.config.max_tokens_director
        }
        
        try:
            response = ollama.chat(
                model=self.config.model_4b,
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': prompt}
                ],
                options={
                    'temperature': temp_map[role],
                    'num_predict': token_map[role],
                    'top_p': 0.9,
                    'top_k': 40
                }
            )
            
            return response['message']['content']
            
        except Exception as e:
            console.print(f"[red]ã‚¨ãƒ©ãƒ¼ ({role}): {e}[/red]")
            return None
    
    def analyze_conversation_state(self):
        """ä¼šè©±ã®çŠ¶æ…‹ã‚’åˆ†æï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        if len(self.conversation_history) < 2:
            return "start"
        
        # æœ€è¿‘ã®ä¼šè©±ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        recent = self.conversation_history[-2:]
        avg_length = sum(len(h['content']) for h in recent) / len(recent)
        
        if avg_length > 300:
            return "too_long"
        elif avg_length < 50:
            return "too_short"
        
        # åŒã˜ã‚ˆã†ãªå¿œç­”ãŒç¶šã„ã¦ã„ã‚‹ã‹
        if self.turn_count > 3 and self.turn_count % 3 == 0:
            return "needs_variation"
        
        return "normal"
    
    def generate_director_instruction(self, state: str):
        """çŠ¶æ…‹ã«å¿œã˜ãŸæ¼”å‡ºæŒ‡ç¤ºã‚’ç”Ÿæˆ"""
        
        instructions = {
            "start": [
                {"to": "narrator", "emotion": "neutral", "length": "medium", "sample": None},
            ],
            "too_long": [
                {"to": "critic", "emotion": "dismissive", "length": "short", "sample": "ã§ï¼Ÿ"},
                {"to": "critic", "emotion": "tired", "length": "short", "sample": "é•·ã„"},
            ],
            "too_short": [
                {"to": "narrator", "emotion": "defensive", "length": "long", "sample": "ã¡ã‚‡ã£ã¨å¾…ã¦ã‚ˆã€èª¬æ˜ã•ã›ã¦"},
            ],
            "needs_variation": [
                {"to": "narrator", "emotion": "angry", "length": "short", "sample": "ã‚‚ã†ã„ã„ï¼"},
                {"to": "critic", "emotion": "sarcastic", "length": "medium", "sample": "ç´ æ™´ã‚‰ã—ã„ã­ï¼ˆçš®è‚‰ï¼‰"},
            ],
            "normal": [
                {"to": "narrator", "emotion": "defensive", "length": "medium", "sample": None},
                {"to": "critic", "emotion": "dismissive", "length": "short", "sample": "ã¤ã¾ã‚‰ãªã„"},
            ]
        }
        
        return random.choice(instructions.get(state, instructions["normal"]))
    
    def run_dialogue(self, theme: str, turns: int = 5):
        """æ”¹å–„ç‰ˆå¯¾è©±å®Ÿè¡Œ"""
        console.print(Panel(f"[bold green]ãƒ†ãƒ¼ãƒ: {theme}[/bold green]", expand=False))
        
        # åˆå›ï¼šèªã‚Šæ‹…å½“ãŒã‚·ãƒ³ãƒ—ãƒ«ã«å§‹ã‚ã‚‹
        console.print("\n[bold magenta]ã€èªã‚Šã€‘[/bold magenta]")
        narrator_prompt = f"æ¬¡ã®ãƒ†ãƒ¼ãƒã§ç‰©èªã‚’å§‹ã‚ã¦ãã ã•ã„ï¼ˆ2-3æ–‡ã§ï¼‰: {theme}"
        narrator_response = self.get_response('narrator', narrator_prompt)
        console.print(f"{Fore.MAGENTA}{narrator_response}{Style.RESET_ALL}")
        self.conversation_history.append({'role': 'narrator', 'content': narrator_response})
        
        for turn in range(turns):
            self.turn_count = turn
            
            # æ‰¹è©•æ‹…å½“ã®å¿œç­”
            console.print("\n[bold cyan]ã€æ‰¹è©•ã€‘[/bold cyan]")
            
            # çŠ¶æ…‹åˆ†æ
            state = self.analyze_conversation_state()
            instruction = self.generate_director_instruction(state)
            
            # æ‰¹è©•å‘ã‘ã®æŒ‡ç¤ºãŒã‚ã‚Œã°é©ç”¨
            if instruction['to'] == 'critic':
                critic_prompt = f"æ¬¡ã‚’æ‰¹è©•ã—ã¦: {narrator_response}"
                if instruction['sample']:
                    critic_prompt = f"ã€Œ{instruction['sample']}ã€ã¨ã„ã†æ„Ÿã˜ã§æ‰¹è©•: {narrator_response}"
            else:
                critic_prompt = f"çŸ­ãæ‰¹è©•ã—ã¦: {narrator_response}"
            
            critic_response = self.get_response('critic', critic_prompt, instruction)
            console.print(f"{Fore.CYAN}{critic_response}{Style.RESET_ALL}")
            self.conversation_history.append({'role': 'critic', 'content': critic_response})
            
            # é€²è¡Œæ‹…å½“ã®ä»‹å…¥ï¼ˆ2ã‚¿ãƒ¼ãƒ³ã”ã¨ï¼‰
            if turn % 2 == 1:
                console.print("\n[dim yellow]ã€é€²è¡ŒæŒ‡ç¤ºã€‘[/dim yellow]")
                instruction = self.generate_director_instruction("needs_variation")
                console.print(f"[dim]{json.dumps(instruction, ensure_ascii=False)}[/dim]")
            
            # èªã‚Šæ‹…å½“ã®åå¿œ
            console.print("\n[bold magenta]ã€èªã‚Šã€‘[/bold magenta]")
            
            if instruction['to'] == 'narrator':
                narrator_prompt = f"æ‰¹è©•ã€Œ{critic_response}ã€ã«å¯¾ã—ã¦ã€{instruction.get('emotion', 'defensive')}ã«å¿œç­”"
                if instruction['sample']:
                    narrator_prompt += f"ã€‚ã€Œ{instruction['sample']}ã€ã‹ã‚‰å§‹ã‚ã¦"
            else:
                narrator_prompt = f"æ‰¹è©•ã€Œ{critic_response}ã€ã«çŸ­ãåè«–"
            
            narrator_response = self.get_response('narrator', narrator_prompt, instruction)
            console.print(f"{Fore.MAGENTA}{narrator_response}{Style.RESET_ALL}")
            self.conversation_history.append({'role': 'narrator', 'content': narrator_response})
            
            console.print("-" * 50)
        
        return self.conversation_history

# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ =====
def main():
    console.print("[bold green]ğŸ­ Gemma3 å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ  - æ”¹å–„ç‰ˆ[/bold green]\n")
    
    # è¨­å®š
    config = SystemConfigV2()
    
    # Ollamaç¢ºèªï¼ˆç°¡ç•¥ç‰ˆï¼‰
    try:
        models = ollama.list()
        console.print("[green]âœ… Ollamaæ¥ç¶šç¢ºèª[/green]")
    except:
        console.print("[red]âŒ Ollamaæ¥ç¶šå¤±æ•—[/red]")
        return 1
    
    # ãƒ†ãƒ¼ãƒé¸æŠ
    themes = [
        "2150å¹´ã®ç«æ˜Ÿã‚³ãƒ­ãƒ‹ãƒ¼ã§ã®æ®ºäººäº‹ä»¶",
        "æ·±å¤œã®ã‚³ãƒ³ãƒ“ãƒ‹ã§èµ·ããŸå¥‡å¦™ãªå‡ºæ¥äº‹",
        "AI ãŒæ‹ã«è½ã¡ãŸæ—¥"
    ]
    
    console.print("ãƒ†ãƒ¼ãƒã‚’é¸æŠ:")
    for i, theme in enumerate(themes, 1):
        console.print(f"  {i}. {theme}")
    
    choice = input("\né¸æŠ (1-3): ").strip()
    theme = themes[int(choice) - 1] if choice.isdigit() and 1 <= int(choice) <= 3 else themes[0]
    
    # å¯¾è©±å®Ÿè¡Œ
    system = ImprovedDialogueSystem(config)
    history = system.run_dialogue(theme, turns=3)
    
    # çµæœä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"outputs/improved_{timestamp}.json"
    
    os.makedirs("outputs", exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'theme': theme,
            'config': {
                'temperature_narrator': config.temperature_narrator,
                'temperature_critic': config.temperature_critic,
                'max_tokens': config.max_tokens_narrator
            },
            'conversation': history
        }, f, ensure_ascii=False, indent=2)
    
    console.print(f"\n[green]âœ… ä¿å­˜å®Œäº†: {output_file}[/green]")
    
    # GPUçŠ¶æ…‹
    console.print("\n[cyan]GPUçŠ¶æ…‹:[/cyan]")
    os.system("nvidia-smi --query-gpu=memory.used,temperature.gpu --format=csv,noheader,nounits")
    
    return 0

if __name__ == "__main__":
    main()